{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118A - Final Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Insert title here***\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Patrick Helcl\n",
    "- Vignesh Jayananth\n",
    "- Rio Aguina-Kang\n",
    "- Christopher Rochez\n",
    "- Kai Stern"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 2 or 3 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Detail how/where you obtained the data and cleaned it (if necessary)\n",
    "\n",
    "If the data cleaning process is very long (e.g., elaborate text processing) consider describing it briefly here in text, and moving the actual clearning process to another notebook in your repo (include a link here!).  The idea behind this approach: this is a report, and if you blow up the flow of the report to include a lot of code it makes it hard to read.\n",
    "\n",
    "Please give the following infomration for each dataset you are using\n",
    "- link/reference to obtain it\n",
    "- description of the size of the dataset (# of variables, # of observations)\n",
    "- what an observation consists of\n",
    "- what some critical variables are, how they are represented\n",
    "- any special handling, transformations, cleaning, etc you have done should be demonstrated here!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Subsection 1\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n",
    "\n",
    "### Subsection 2\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data\n",
    "\n",
    "### Subsection 3\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n",
    "\n",
    "### Subsection 4\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n",
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *** Code starts below***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Price</th>\n",
       "      <th>Day</th>\n",
       "      <th>Room Type</th>\n",
       "      <th>Shared Room</th>\n",
       "      <th>Private Room</th>\n",
       "      <th>Person Capacity</th>\n",
       "      <th>Superhost</th>\n",
       "      <th>Multiple Rooms</th>\n",
       "      <th>Business</th>\n",
       "      <th>Cleanliness Rating</th>\n",
       "      <th>Guest Satisfaction</th>\n",
       "      <th>Bedrooms</th>\n",
       "      <th>City Center (km)</th>\n",
       "      <th>Metro Distance (km)</th>\n",
       "      <th>Attraction Index</th>\n",
       "      <th>Normalised Attraction Index</th>\n",
       "      <th>Restraunt Index</th>\n",
       "      <th>Normalised Restraunt Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>194.033698</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Private room</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.022964</td>\n",
       "      <td>2.539380</td>\n",
       "      <td>78.690379</td>\n",
       "      <td>4.166708</td>\n",
       "      <td>98.253896</td>\n",
       "      <td>6.846473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>344.245776</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Private room</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.488389</td>\n",
       "      <td>0.239404</td>\n",
       "      <td>631.176378</td>\n",
       "      <td>33.421209</td>\n",
       "      <td>837.280757</td>\n",
       "      <td>58.342928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>264.101422</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Private room</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.748312</td>\n",
       "      <td>3.651621</td>\n",
       "      <td>75.275877</td>\n",
       "      <td>3.985908</td>\n",
       "      <td>95.386955</td>\n",
       "      <td>6.646700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>433.529398</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Private room</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.384862</td>\n",
       "      <td>0.439876</td>\n",
       "      <td>493.272534</td>\n",
       "      <td>26.119108</td>\n",
       "      <td>875.033098</td>\n",
       "      <td>60.973565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amsterdam</td>\n",
       "      <td>485.552926</td>\n",
       "      <td>Weekday</td>\n",
       "      <td>Private room</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544738</td>\n",
       "      <td>0.318693</td>\n",
       "      <td>552.830324</td>\n",
       "      <td>29.272733</td>\n",
       "      <td>815.305740</td>\n",
       "      <td>56.811677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41709</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>715.938574</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.530181</td>\n",
       "      <td>0.135447</td>\n",
       "      <td>219.402478</td>\n",
       "      <td>15.712158</td>\n",
       "      <td>438.756874</td>\n",
       "      <td>10.604584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41710</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>304.793960</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.810205</td>\n",
       "      <td>0.100839</td>\n",
       "      <td>204.970121</td>\n",
       "      <td>14.678608</td>\n",
       "      <td>342.182813</td>\n",
       "      <td>8.270427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41711</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>637.168969</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.994051</td>\n",
       "      <td>0.202539</td>\n",
       "      <td>169.073402</td>\n",
       "      <td>12.107921</td>\n",
       "      <td>282.296424</td>\n",
       "      <td>6.822996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41712</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>301.054157</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Private room</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.044100</td>\n",
       "      <td>0.287435</td>\n",
       "      <td>109.236574</td>\n",
       "      <td>7.822803</td>\n",
       "      <td>158.563398</td>\n",
       "      <td>3.832416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41713</th>\n",
       "      <td>Vienna</td>\n",
       "      <td>133.230489</td>\n",
       "      <td>Weekend</td>\n",
       "      <td>Private room</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.263932</td>\n",
       "      <td>0.480903</td>\n",
       "      <td>150.450381</td>\n",
       "      <td>10.774264</td>\n",
       "      <td>225.247293</td>\n",
       "      <td>5.444140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41714 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            City       Price      Day        Room Type  Shared Room  \\\n",
       "0      Amsterdam  194.033698  Weekday     Private room        False   \n",
       "1      Amsterdam  344.245776  Weekday     Private room        False   \n",
       "2      Amsterdam  264.101422  Weekday     Private room        False   \n",
       "3      Amsterdam  433.529398  Weekday     Private room        False   \n",
       "4      Amsterdam  485.552926  Weekday     Private room        False   \n",
       "...          ...         ...      ...              ...          ...   \n",
       "41709     Vienna  715.938574  Weekend  Entire home/apt        False   \n",
       "41710     Vienna  304.793960  Weekend  Entire home/apt        False   \n",
       "41711     Vienna  637.168969  Weekend  Entire home/apt        False   \n",
       "41712     Vienna  301.054157  Weekend     Private room        False   \n",
       "41713     Vienna  133.230489  Weekend     Private room        False   \n",
       "\n",
       "       Private Room  Person Capacity  Superhost  Multiple Rooms  Business  \\\n",
       "0              True              2.0      False               1         0   \n",
       "1              True              4.0      False               0         0   \n",
       "2              True              2.0      False               0         1   \n",
       "3              True              4.0      False               0         1   \n",
       "4              True              2.0       True               0         0   \n",
       "...             ...              ...        ...             ...       ...   \n",
       "41709         False              6.0      False               0         1   \n",
       "41710         False              2.0      False               0         0   \n",
       "41711         False              2.0      False               0         0   \n",
       "41712          True              2.0      False               0         0   \n",
       "41713          True              4.0       True               1         0   \n",
       "\n",
       "       Cleanliness Rating  Guest Satisfaction  Bedrooms  City Center (km)  \\\n",
       "0                    10.0                93.0         1          5.022964   \n",
       "1                     8.0                85.0         1          0.488389   \n",
       "2                     9.0                87.0         1          5.748312   \n",
       "3                     9.0                90.0         2          0.384862   \n",
       "4                    10.0                98.0         1          0.544738   \n",
       "...                   ...                 ...       ...               ...   \n",
       "41709                10.0               100.0         3          0.530181   \n",
       "41710                 8.0                86.0         1          0.810205   \n",
       "41711                10.0                93.0         1          0.994051   \n",
       "41712                10.0                87.0         1          3.044100   \n",
       "41713                10.0                93.0         1          1.263932   \n",
       "\n",
       "       Metro Distance (km)  Attraction Index  Normalised Attraction Index  \\\n",
       "0                 2.539380         78.690379                     4.166708   \n",
       "1                 0.239404        631.176378                    33.421209   \n",
       "2                 3.651621         75.275877                     3.985908   \n",
       "3                 0.439876        493.272534                    26.119108   \n",
       "4                 0.318693        552.830324                    29.272733   \n",
       "...                    ...               ...                          ...   \n",
       "41709             0.135447        219.402478                    15.712158   \n",
       "41710             0.100839        204.970121                    14.678608   \n",
       "41711             0.202539        169.073402                    12.107921   \n",
       "41712             0.287435        109.236574                     7.822803   \n",
       "41713             0.480903        150.450381                    10.774264   \n",
       "\n",
       "       Restraunt Index  Normalised Restraunt Index  \n",
       "0            98.253896                    6.846473  \n",
       "1           837.280757                   58.342928  \n",
       "2            95.386955                    6.646700  \n",
       "3           875.033098                   60.973565  \n",
       "4           815.305740                   56.811677  \n",
       "...                ...                         ...  \n",
       "41709       438.756874                   10.604584  \n",
       "41710       342.182813                    8.270427  \n",
       "41711       282.296424                    6.822996  \n",
       "41712       158.563398                    3.832416  \n",
       "41713       225.247293                    5.444140  \n",
       "\n",
       "[41714 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw data and necessary imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "airbnb = pd.read_csv('https://raw.githubusercontent.com/COGS118A/Group023-SP23/main/Aemf1.csv')\n",
    "airbnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 best features: ['Private Room', 'Attraction Index', 'Restraunt Index', 'Shared Room', 'Superhost', 'Day', 'Cleanliness Rating', 'City Center (km)', 'Guest Satisfaction', 'Metro Distance (km)']\n",
      "R-squared error: 0.23523088550530946\n",
      "RMSE: 249.31775255825627\n",
      "Mean Absolute Error: 87.27274172615812\n",
      "all features and their weights in dictionary below\n",
      "{'City': -106562739864030.14, 'Day': -106562739864517.62, 'Room Type': -106562739864310.39, 'Person Capacity': -106562739864296.56, 'Cleanliness Rating': -106562739864478.38, 'Guest Satisfaction': -106562739864412.66, 'Bedrooms': -106562739864234.67, 'City Center (km)': -106562739864457.86, 'Metro Distance (km)': -106562739864382.75, 'Attraction Index': -2961601775058185.5, 'Restraunt Index': -2961601775058182.5, 'Shared Room': 2263810158132507.5, 'Private Room': 2978274052053386.5, 'Superhost': 1851854018619729.5, 'Multiple Rooms': 27.171875, 'Business': 4.08984375}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# dropping normalized columns since pipeline will normalize all scalar columns\n",
    "\n",
    "airbnb = airbnb.drop(columns=['Normalised Attraction Index', 'Normalised Restraunt Index'])\n",
    "\n",
    "# code below preforms a multi linear regrssion, using all columns\n",
    "\n",
    "X = airbnb.drop('Price', axis=1)  \n",
    "y = airbnb['Price']  \n",
    "\n",
    "# column name lists for pipeline later\n",
    "categorical_cols = ['City', 'Day', 'Room Type']\n",
    "\n",
    "numeric_cols = ['Person Capacity', 'Cleanliness Rating', 'Guest Satisfaction', 'Bedrooms',\n",
    "                'City Center (km)', 'Metro Distance (km)', 'Attraction Index', 'Restraunt Index']\n",
    "\n",
    "boolean_cols = ['Shared Room', 'Private Room', 'Superhost', 'Multiple Rooms', 'Business']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# One hot encodes categorical columns specified above, normalizes\n",
    "# sclar columns and leaves boolean columns as is\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('to categorical', OneHotEncoder(), categorical_cols),\n",
    "        ('standardize', StandardScaler(), numeric_cols),\n",
    "        ('bool', 'passthrough', boolean_cols)])\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "regressor_weights = pipeline.named_steps['regressor'].coef_\n",
    "\n",
    "feature_weights = dict(zip(categorical_cols + numeric_cols + boolean_cols, regressor_weights))\n",
    "\n",
    "# sorts features by absolute value of weight's magnitude to find most important ones later\n",
    "sorted_features = sorted(feature_weights.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "\n",
    "# gets 10 most important features out of 16 total columns (price not included)\n",
    "\n",
    "num_best_features = 10  \n",
    "best_features = [feature for feature, _ in sorted_features[:num_best_features]]\n",
    "\n",
    "# fits pipeline/ linear regression obj\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print('10 best features:', best_features)\n",
    "print(f\"R-squared error: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print('all features and their weights in dictionary below')\n",
    "print(feature_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Shared Room': 3831,\n",
       " 'Private Room': 5722,\n",
       " 'Superhost': 6435,\n",
       " 'City': 6585,\n",
       " 'Bedrooms': 6631,\n",
       " 'Person Capacity': 6671,\n",
       " 'Room Type': 6702,\n",
       " 'Metro Distance (km)': 6741,\n",
       " 'Guest Satisfaction': 6752,\n",
       " 'City Center (km)': 6778,\n",
       " 'Cleanliness Rating': 6804,\n",
       " 'Day': 6828,\n",
       " 'Attraction Index': 7237,\n",
       " 'Restraunt Index': 7291,\n",
       " 'Multiple Rooms': 13994,\n",
       " 'Business': 14998}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cell block measures position of each variable with respect to weights in sorted importance\n",
    "# lower score in final dictionary means more important features and vice versa\n",
    "# note: runtime for this block ~ 5mins and 20 seconds\n",
    "\n",
    "score_dict = {'City':0, 'Day':0, 'Room Type':0 ,'Person Capacity':0 , 'Cleanliness Rating':0, 'Guest Satisfaction':0,\n",
    "            'Bedrooms':0, 'City Center (km)':0, 'Metro Distance (km)':0, 'Attraction Index':0, 'Restraunt Index':0, \n",
    "            'Shared Room':0, 'Private Room':0, 'Superhost':0, 'Multiple Rooms':0, 'Business':0}\n",
    "\n",
    "#1000 simulations to reduce sample bias\n",
    "\n",
    "for _ in range(1000):\n",
    "    X = airbnb.drop(columns='Price', axis=1)  \n",
    "    y = airbnb['Price']  \n",
    "\n",
    "    categorical_cols = ['City', 'Day', 'Room Type']\n",
    "    \n",
    "    numeric_cols = ['Person Capacity', 'Cleanliness Rating', 'Guest Satisfaction', 'Bedrooms',\n",
    "                    'City Center (km)', 'Metro Distance (km)', 'Attraction Index',\n",
    "                    'Restraunt Index']\n",
    "\n",
    "    boolean_cols = ['Shared Room', 'Private Room', 'Superhost', 'Multiple Rooms', 'Business']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers=[\n",
    "                        ('to categorical', OneHotEncoder(), categorical_cols), \n",
    "                        ('standardize', StandardScaler(), numeric_cols), \n",
    "                        ('bool', 'passthrough', boolean_cols)])\n",
    "\n",
    "    pipeline = Pipeline([('preprocessor', preprocessor), ('regressor', LinearRegression())])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    regressor_weights = pipeline.named_steps['regressor'].coef_\n",
    "    feature_weights = dict(zip(categorical_cols + numeric_cols + boolean_cols, regressor_weights))\n",
    "    sorted_features = sorted(feature_weights.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "    best_features = [feature for feature, _ in sorted_features]\n",
    "\n",
    "    for j in best_features:\n",
    "        score_dict[j] += best_features.index(j)\n",
    "\n",
    "sorted_dict = dict(sorted(score_dict.items(), key=lambda x: x[1]))\n",
    "sorted_dict\n",
    "\n",
    "# results below sorted by most important (top/ lowest score) to least important (bottom/highest score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous results for comparison with output above:\n",
    "# {'Shared Room': 3727,\n",
    "#  'Private Room': 5521,\n",
    "#  'Superhost': 6450,\n",
    "#  'Day': 6757,\n",
    "#  'Cleanliness Rating': 6774,\n",
    "#  'City Center (km)': 6791,\n",
    "#  'Guest Satisfaction': 6813,\n",
    "#  'City': 6822,\n",
    "#  'Bedrooms': 6838,\n",
    "#  'Metro Distance (km)': 6843,\n",
    "#  'Person Capacity': 6846,\n",
    "#  'Room Type': 6851,\n",
    "#  'Restraunt Index': 6996,\n",
    "#  'Attraction Index': 7000,\n",
    "#  'Multiple Rooms': 13983,\n",
    "#  'Business': 14988}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared error: 0.21247247242064338\n",
      "RMSE: 263.9955150843865\n",
      "Mean Absolute Error: 92.14160395157168\n"
     ]
    }
   ],
   "source": [
    "# from code above we consistently see the features:\n",
    "# 'Day', 'City', 'Cleanliness Rating', 'City Center (km)','Guest Satisfaction','Bedrooms',\n",
    "# 'Shared Room', 'Private Room', 'Superhost' amongst the most heavily weighted features\n",
    "# meaning our model consideres these the most when prediciting price for airbnb\n",
    "\n",
    "X = airbnb.drop('Price', axis=1) \n",
    "y = airbnb['Price']  \n",
    "\n",
    "# now we try using another simpler linear regression\n",
    "# with aformentioned columns:\n",
    "\n",
    "categorical_cols = ['Day', 'City'] \n",
    "numeric_cols = ['Cleanliness Rating', 'City Center (km)','Guest Satisfaction','Bedrooms']\n",
    "boolean_cols = ['Shared Room', 'Private Room', 'Superhost']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('to categorical', OneHotEncoder(), categorical_cols),\n",
    "        ('standarize', StandardScaler(), numeric_cols),\n",
    "        ('bool', 'passthrough', boolean_cols)])\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "regressor_weights = pipeline.named_steps['regressor'].coef_\n",
    "feature_weights = dict(zip(categorical_cols + numeric_cols + boolean_cols, regressor_weights))\n",
    "\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"R-squared error: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# with just these columns we have a very similar MAE to model using all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up graph of n-features and MAE\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# potentially try grid search for feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared error: 0.3307030404867324\n",
      "RMSE: 294.06644557974306\n",
      "Mean Absolute Error: 58.317394939615404\n"
     ]
    }
   ],
   "source": [
    "# Decision tree regressor on all columns:\n",
    "\n",
    "# same logic and steps as original Linear regression\n",
    "# using all columns only with different model\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X = airbnb.drop('Price', axis=1)  \n",
    "y = airbnb['Price']  \n",
    "\n",
    "categorical_cols = ['City', 'Day', 'Room Type']\n",
    "\n",
    "numeric_cols = ['Person Capacity', 'Cleanliness Rating', 'Guest Satisfaction', 'Bedrooms',\n",
    "                'City Center (km)', 'Metro Distance (km)', 'Attraction Index','Restraunt Index']\n",
    "\n",
    "boolean_cols = ['Shared Room', 'Private Room', 'Superhost', 'Multiple Rooms', 'Business']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('to categorical', OneHotEncoder(), categorical_cols),\n",
    "        ('standarize', StandardScaler(), numeric_cols),\n",
    "        ('bool', 'passthrough', boolean_cols)  \n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', DecisionTreeRegressor())  \n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"R-squared error: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# tends to have much lower MAE then either Linear regression above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Decision tree regressor using pruned columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared error: 0.5581422010868171\n",
      "RMSE: 201.74174398391656\n",
      "Mean Absolute Error: 51.18094131686579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# note runtime for block ~ 35 seconds\n",
    "\n",
    "X = airbnb.drop('Price', axis=1) \n",
    "y = airbnb['Price'] \n",
    "\n",
    "categorical_cols = ['City', 'Day', 'Room Type']\n",
    "\n",
    "numeric_cols = ['Person Capacity', 'Cleanliness Rating', 'Guest Satisfaction', 'Bedrooms',\n",
    "                'City Center (km)', 'Metro Distance (km)', 'Attraction Index',\n",
    "                 'Restraunt Index']\n",
    "\n",
    "boolean_cols = ['Shared Room', 'Private Room', 'Superhost', 'Multiple Rooms', 'Business']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('to categorical', OneHotEncoder(), categorical_cols),\n",
    "        ('standarize', StandardScaler(), numeric_cols),\n",
    "        ('bool', 'passthrough', boolean_cols)])\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor())]) # standard estimators in forest = 100\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(f\"R-squared error: {r2}\")\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\") \n",
    "\n",
    "# Seems to have much lower MAE then either Linear regression above"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
